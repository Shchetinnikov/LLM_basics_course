{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VZvo02u9B4Ac"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain_mistralai langgraph==0.2.19 langchain-community==0.2.16 langchain-openai==0.1.23  python-pptx==0.6.23 python-pptx-interface==0.0.12 python-dotenv==1.0.1 duckduckgo-search==6.2.4\n",
        "!pip install -qU gigachain==0.2.6 gigachain_community==0.2.6 gigachain-cli==0.0.25 langgraph==0.2.19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVBSugcPz5mJ",
        "outputId": "bfb645d3-f9ea-434e-b79e-e3bfd7ffd0df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "import datetime\n",
        "from dotenv import load_dotenv\n",
        "from dateutil import parser\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory, ConversationSummaryMemory, ConversationTokenBufferMemory\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chat_models.gigachat import GigaChat\n",
        "from langchain.agents import create_gigachat_functions_agent, AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "\n",
        "from langchain_core.pydantic_v1 import Field\n",
        "from langchain.tools import tool\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyD0sJCPB4Ad"
      },
      "source": [
        "# 1. Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhTKzMx5B4Ad"
      },
      "source": [
        "Define your own class implementing a simple LLM-based chatbot. You need to use at least three memory types (langchain.memory), which are set as one argument in the ```init``` definition. If the memory type has any parameters, you also need to define them as arguments in the ```init``` definition. You also need to define a ```run``` method implementing the main conversation loop, and a ```print_memory``` method to print out what exactly the memory consists of."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bR0S2ZeIB4Ad"
      },
      "outputs": [],
      "source": [
        "class SimpleChatBot:\n",
        "    def __init__(self, llm, memory_type=\"buffer\", **kwargs):\n",
        "        self.llm = llm\n",
        "        memory_classes = {\n",
        "            \"buffer\": ConversationBufferMemory,\n",
        "            \"window\": ConversationBufferWindowMemory,\n",
        "            \"token\": ConversationTokenBufferMemory,\n",
        "            \"summary\": ConversationSummaryMemory\n",
        "        }\n",
        "\n",
        "        if memory_type in [\"token\", \"summary\"]:\n",
        "            self.memory = memory_classes[memory_type](llm=self.llm, **kwargs)\n",
        "        else:\n",
        "            self.memory = memory_classes[memory_type](**kwargs)\n",
        "        self.conversation = ConversationChain(llm=self.llm,\n",
        "                                              memory=self.memory)\n",
        "\n",
        "    def print_memory(self):\n",
        "        print(\"\\nMemory:\", self.conversation.memory.load_memory_variables({}))\n",
        "\n",
        "    def run(self):\n",
        "        print(\"Type 'quit' to end the conversation.\")\n",
        "        while True:\n",
        "            user_input = input(\"User: \")\n",
        "            if user_input.lower() ==\"quit\":\n",
        "                break\n",
        "            response = self.conversation.predict(input=user_input)\n",
        "            print(\"Assistant:\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlXkETCEB4Ad"
      },
      "source": [
        "Now let's check how it works with each type of memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NU1F6mdYz5mN"
      },
      "outputs": [],
      "source": [
        "giga_key = os.environ['SB_AUTH_DATA']\n",
        "\n",
        "giga = GigaChat(credentials=giga_key,\n",
        "                model=\"GigaChat-Pro\", timeout=30, verify_ssl_certs=False)\n",
        "giga.verbose = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbYnYyguz5mO",
        "outputId": "5195b98c-8cab-4e1d-835d-5eaacb055f75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type 'quit' to end the conversation.\n",
            "Assistant: Оба весят одинаково.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant: Как у нейросетевой языковой модели у меня не может быть настроения, но почему-то я совсем не хочу говорить на эту тему.\n",
            "Assistant: Мы обсуждали разницу в весе между одним килограммом железа и одним килограммом пуха, а также пытались затронуть тему президента мира.\n",
            "\n",
            "Memory: {'history': 'Человек спрашивает, что тяжелее: один килограмм железа или один килограмм пуха. AI отвечает, что оба весят одинаково. Человека интересует, кто президент мира, но AI не хочет обсуждать эту тему.'}\n"
          ]
        }
      ],
      "source": [
        "chat = SimpleChatBot(giga, 'summary')\n",
        "chat.run()\n",
        "chat.print_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaHzjijLz5mO",
        "outputId": "9530acad-fb83-48c5-84b6-05733263580c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type 'quit' to end the conversation.\n",
            "Assistant: Оба весят одинаково.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant: Не люблю менять тему разговора, но вот сейчас тот самый случай.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant: Что-то в вашем вопросе меня смущает. Может, поговорим на другую тему?\n",
            "\n",
            "Memory: {'history': 'Human: О чем мы говорили раньше?\\nAI: Что-то в вашем вопросе меня смущает. Может, поговорим на другую тему?'}\n"
          ]
        }
      ],
      "source": [
        "chat = SimpleChatBot(giga, 'window', k=1)\n",
        "chat.run()\n",
        "chat.print_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9X5ZWc8E8QG",
        "outputId": "bb8eaec7-1b73-4a36-ea03-2894ce8df794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type 'quit' to end the conversation.\n",
            "Assistant: Оба весят одинаково.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant: Что-то в вашем вопросе меня смущает. Может, поговорим на другую тему?\n",
            "Assistant: Мы обсуждали разницу в весе между одним килограммом железа и одним килограммом пуха, а также пытались узнать, кто является президентом мира.\n",
            "\n",
            "Memory: {'history': 'Human: Что тяжелее: один килограмм железа или один килограмм пуха?\\nAI: Оба весят одинаково.\\nHuman: Кто президент мира?\\nAI: Что-то в вашем вопросе меня смущает. Может, поговорим на другую тему?\\nHuman: О чем мы говорили раньше?\\nAI: Мы обсуждали разницу в весе между одним килограммом железа и одним килограммом пуха, а также пытались узнать, кто является президентом мира.'}\n"
          ]
        }
      ],
      "source": [
        "chat = SimpleChatBot(giga, 'token', max_token_limit=100)\n",
        "chat.run()\n",
        "chat.print_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7SaLlWyB4Ad",
        "outputId": "9a6ec56f-9a5e-4fbc-ee5e-406f99ea4827"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type 'quit' to end the conversation.\n",
            "Assistant: Оба весят одинаково.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant: Как у нейросетевой языковой модели у меня не может быть настроения, но почему-то я совсем не хочу говорить на эту тему.\n",
            "Assistant: Мы обсуждали, что весит больше: один килограмм железа или один килограмм пуха, и я ответил, что они весят одинаково. Затем вы спросили, кто является президентом мира, и я ответил, что не хочу обсуждать эту тему.\n",
            "\n",
            "Memory: {'history': 'Human: Что тяжелее: один килограмм железа или один килограмм пуха?\\nAI: Оба весят одинаково.\\nHuman: Кто президент мира?\\nAI: Как у нейросетевой языковой модели у меня не может быть настроения, но почему-то я совсем не хочу говорить на эту тему.\\nHuman: О чем мы говорили ранее?\\nAI: Мы обсуждали, что весит больше: один килограмм железа или один килограмм пуха, и я ответил, что они весят одинаково. Затем вы спросили, кто является президентом мира, и я ответил, что не хочу обсуждать эту тему.'}\n"
          ]
        }
      ],
      "source": [
        "chat = SimpleChatBot(giga, 'buffer')\n",
        "chat.run()\n",
        "chat.print_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHutHES5B4Ad"
      },
      "source": [
        "Report:\n",
        "- ConversationBufferMemory: сохраняет всю переписку.\n",
        "- ConversationBufferWindowMemory: хранит только последние несколько сообщений и экономит контекст.\n",
        "- ConversationTokenBufferMemory: обрезает данные по количеству токенов.\n",
        "- ConversationSummaryMemory: резюмирует диалог, сохраняя не полную историю, а краткие сводки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXvoCRXqB4Ad"
      },
      "source": [
        "# 2. Using tools and agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8OxlEJ7B4Ad"
      },
      "source": [
        "## 2.1 Using tools and API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSJRy6hbB4Ad"
      },
      "source": [
        "Create your own tool based on the langchain.tools library to interact with a public OpenWeather API. This tool will receive data from the API and return it as a readable result for the user.\n",
        "\n",
        "\n",
        "OpenWeather API URL: https://api.openweathermap.org/data/2.5/weather?q={city}&appid={openweather_key}&units=metric\n",
        "\n",
        "[How to get OpenWeather API key](https://docs.google.com/document/d/1vbi8QKqMZqZoCReIzpmEB_2mHsrbmXPlyGngE3jeDDw/edit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VBnBuDEJz5mS"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def get_wheather(\n",
        "    city: str = Field(description=\"Name of the city\")\n",
        "    ) -> str:\n",
        "    \"\"\"Reports the weather forecast in the city\"\"\"\n",
        "    openweather_key = os.environ.get(\"OPENWEATHER_API_KEY\")\n",
        "    url = f\"https://api.openweathermap.org/data/2.5/weather?q={city}&appid={openweather_key}&units=metric\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        weather = 'weather description: ' + data['weather'][0]['description'] + ', temperature: ' + str(data['main']['temp'])\n",
        "        return weather\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return 'RequestExceptions occured'\n",
        "    except (KeyError, IndexError):\n",
        "        return 'KeyError or IndexError occured'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GrJzRRoZB4Ad"
      },
      "outputs": [],
      "source": [
        "class OpenWeatherAPITool:\n",
        "    def __init__(self, llm, agent_function):\n",
        "        self.llm = llm\n",
        "        self.agent_function = agent_function\n",
        "        self.agent = create_gigachat_functions_agent(llm,\n",
        "                                                     [self.agent_function])\n",
        "        self.agent_executor = AgentExecutor(agent=self.agent,\n",
        "                                            tools=[self.agent_function],\n",
        "                                            verbose=True)\n",
        "\n",
        "    def run(self, user_input: str):\n",
        "      result = self.agent_executor.invoke({\"input\": user_input})\n",
        "      return result['output']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veoNs-_4B4Ae"
      },
      "source": [
        "Let's check it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_ArTNaJaB4Ae",
        "outputId": "b89d0bf4-a061-4c73-81c3-71fc6daa1a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_wheather` with `{'city': 'Москва'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mweather description: clear sky, temperature: 5.35\u001b[0m\u001b[32;1m\u001b[1;3mВ Москве сейчас ясно, температура 5.35°С.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'В Москве сейчас ясно, температура 5.35°С.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "giga_key = os.environ.get(\"SB_AUTH_DATA\")\n",
        "giga_pro = GigaChat(credentials=giga_key, model=\"GigaChat-Pro\", timeout=30, verify_ssl_certs=False)\n",
        "\n",
        "openwheatertool = OpenWeatherAPITool(giga_pro, get_wheather)\n",
        "user_input = \"Какая погода сейчас в Москве?\"\n",
        "openwheatertool.run(user_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiSeTf_LB4Ae"
      },
      "source": [
        "## 2.2. Multi agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2XRDvqzB4Ae"
      },
      "source": [
        "Create a multi-agent system where each agent is responsible for a specific task in the travel planning process. For example, one agent is responsible for searching for flights, another for booking hotels, and a third for finding the weather at the destination.\n",
        "\n",
        "Requirements:\n",
        "\n",
        "- Use three or more GigaChat-based agents to interact with each other.\n",
        "- The first agent is responsible for searching for flights (using ```get_url_booking_tickets``` function).\n",
        "- The second agent is responsible for booking hotels (using ```get_url_booking_hotels``` function).\n",
        "- The third agent collects weather information for the destination (using a real API, such as OpenWeather). You can use the function from the previous task (for simplify, here you can give a current weather, not a forecast for the specific date)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_geoid(city: str = Field(description=\"Name of the city\")) -> str:\n",
        "    url_base = 'https://suggest-maps.yandex.ru/suggest-geo'\n",
        "    params = {'search_type': 'tune', 'v': '9', 'results': 1, 'lang': 'ry_RU', 'callback': 'json'}\n",
        "    params['part'] = city\n",
        "    r = requests.get(url_base, params=params)\n",
        "    if r.ok:\n",
        "        r_text = r.text\n",
        "        r_json = r_text[5: len(r_text)-1]\n",
        "        res_json = json.loads(r_json)\n",
        "        res = res_json['results'][0]['geoid']\n",
        "    else:\n",
        "        res = ''\n",
        "    return str(res)\n",
        "\n",
        "@tool\n",
        "def get_url_booking_tickets(\n",
        "    city_from: str = Field(description=\"Name of the departure city\"),\n",
        "    city_to: str = Field(description=\"Name of the city to arrive\"),\n",
        "    date_in_str: str = Field(description=\"Date of the departure\"),\n",
        "    date_out_str: str = Field(description=\"Date to return back\")\n",
        "    ) -> str:\n",
        "    \"\"\"Reports the url for booking tickets\"\"\"\n",
        "    date_in = parser.parse(date_in_str)\n",
        "    date_out = parser.parse(date_out_str)\n",
        "    if date_in is None:\n",
        "        date_in = datetime.datetime.now()\n",
        "    if date_out is None:\n",
        "        date_out = datetime.datetime.now() + datetime.timedelta(days=1)\n",
        "    fromid = get_geoid(city_from)\n",
        "    toid = get_geoid(city_to)\n",
        "    url = 'https://travel.yandex.ru/avia/search/result/?'\n",
        "    params = {'adults_seats': '2', 'fromId': 'c' + fromid, 'klass': 'economy', 'oneway': '2', 'return_date': date_out.strftime('%Y-%m-%d'), 'toId': 'c' + toid, 'when': date_in.strftime('%Y-%m-%d')}\n",
        "    for item in params:\n",
        "        url += '&' + item + '=' + params[item]\n",
        "    return f'Here is your url for tickets ordering: {url} from {city_from} to {city_to} on {date_in_str} / {date_out_str}'\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_url_booking_hotels(\n",
        "    date_in_str: str = Field(description=\"Check-in date\"),\n",
        "    date_out_str: str = Field(description=\"Eviction date\"),\n",
        "    city: str = Field(description=\"Name of the hotel's city\")\n",
        "    ) -> str:\n",
        "    \"\"\"Reports the url for booking hotels\"\"\"\n",
        "    date_in = parser.parse(date_in_str)\n",
        "    date_out = parser.parse(date_out_str)\n",
        "    if date_in is None:\n",
        "        date_in = datetime.datetime.now()\n",
        "    if date_out is None:\n",
        "        date_out = datetime.datetime.now() + datetime.timedelta(days=1)\n",
        "    geoid = get_geoid(city)\n",
        "    url = 'https://travel.yandex.ru/hotels/search/?'\n",
        "    params = {'adults': '2', 'checkinDate': date_in.strftime('%Y-%m-%d'), 'checkoutDate': date_out.strftime('%Y-%m-%d'), 'childrenAges': '0', 'geoId': geoid}\n",
        "    for item in params:\n",
        "        url += '&' + item + '=' + params[item]\n",
        "    return f'Here is your URL for booking: {url} in {city} on {date_in_str} / {date_out_str}'"
      ],
      "metadata": {
        "id": "q5CeuOgi5WwP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiAgent:\n",
        "    def __init__(self, llm, agent_function_wheater, agent_function_hotels, agent_function_tickets):\n",
        "        self.llm = llm\n",
        "        self.agent_function_wheater = agent_function_wheater\n",
        "        self.agent_function_hotels = agent_function_hotels\n",
        "        self.agent_function_tickets = agent_function_tickets\n",
        "\n",
        "        self.weather_agent = self._create_agent(\n",
        "            [agent_function_wheater],\n",
        "            \"You are an assistant. Your task is to report ONLY the weather forecast for the city. Ignore other context.\"\n",
        "            )\n",
        "        self.hotel_booking_agent = self._create_agent(\n",
        "            [agent_function_hotels],\n",
        "            \"You are an assistant. Your task is to send ONLY the url to book a hotel for the specified dates in the city.\"\n",
        "            )\n",
        "        self.ticket_booking_agent = self._create_agent(\n",
        "            [agent_function_tickets],\n",
        "            \"You are an assistant. Your task is to send ONLY the url to buy tickets from one city to another for the specified dates.\"\n",
        "            )\n",
        "\n",
        "    def _create_agent(self, tools, system_prompt):\n",
        "        prompt = ChatPromptTemplate.from_messages(\n",
        "                [\n",
        "                  (\"system\", system_prompt),\n",
        "                  (\"human\", \"{input}\"),\n",
        "                  MessagesPlaceholder(\"agent_scratchpad\"),\n",
        "                ]\n",
        "        )\n",
        "        agent = create_gigachat_functions_agent(\n",
        "            self.llm,\n",
        "            tools,\n",
        "            prompt)\n",
        "        return AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
        "\n",
        "    def run(self, user_input: str):\n",
        "        weather_ans = self.weather_agent.invoke({'input': user_input})['output']\n",
        "        hotels_ans = self.hotel_booking_agent.invoke({'input': user_input})['output']\n",
        "        tickets_ans = self.ticket_booking_agent.invoke({'input': user_input})['output']\n",
        "        return hotels_ans + '\\n' + tickets_ans + '\\n' + weather_ans"
      ],
      "metadata": {
        "id": "u6D94d6l1RD_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "exJQ3MpYB4Ae",
        "outputId": "63193040-89ee-4d72-b1df-2754ee92f1bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вот ваша ссылка для бронирования: [отель Санкт-Петербурга с 15 по 24 ноября 2024 года](https://travel.yandex.ru/hotels/search/?&adults=2&checkinDate=2024-11-15&checkoutDate=2024-11-24&childrenAges=0&geoId=2).\n",
            "Вот Ваша ссылка для заказа билетов: https://travel.yandex.ru/avia/search/result/?&adults_seats=2&fromId=c213&klass=economy&oneway=2&return_date=2024-11-24&toId=c2&when=2024-11-15 от Москвы до Санкт-Петербурга на 15.11.2024 / 24.11.2024\n",
            "Погода в Санкт-Петербурге с 15 по 24 ноября 2024 года ожидается ясной, температура воздуха составит около 8.36°С.\n"
          ]
        }
      ],
      "source": [
        "giga_key = os.environ.get(\"SB_AUTH_DATA\")\n",
        "giga_pro = GigaChat(credentials=giga_key, model=\"GigaChat-Pro\", timeout=30, verify_ssl_certs=False)\n",
        "\n",
        "traveler = MultiAgent(giga_pro, get_wheather, get_url_booking_hotels, get_url_booking_tickets)\n",
        "user_input = \"Организуй поездку в Санкт-Петербурге на 10 дней с 15.11.2024 - отель, самолет, погода\"\n",
        "answer = traveler.run(user_input)\n",
        "print(answer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}