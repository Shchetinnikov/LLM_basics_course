{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uE1FNWfS-L5D"
      },
      "outputs": [],
      "source": [
        "#!pip install keybert spacy sklearn sentence_transformers langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLTya3-t-L5F"
      },
      "source": [
        "# Продвинутые техники RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-td9QkK7-L5I"
      },
      "source": [
        "## 1. Сжатие промптов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T_KBVT7-L5J"
      },
      "source": [
        "### 1.1. Зачем нужно сжатие промптов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVBo2k2N-L5K"
      },
      "source": [
        "**Проблема ресурсоемкости**: Каждый запрос в LLM (Language Model) ограничен по количеству символов, а большие промпты требуют значительных вычислительных мощностей. Сокращение промпта — это способ повысить производительность и сделать процесс более экономичным.\n",
        "\n",
        "**Улучшение скорости обработки**: Сжатие промптов ускоряет время обработки запроса и может повысить общую точность ответа, так как модель обрабатывает только ключевую информацию.\n",
        "\n",
        "**Фокус на релевантной информации**: В больших промптах часто много избыточной информации, и задача сжатия — выделить только необходимые элементы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq_SrMiI-L5L"
      },
      "source": [
        "### 1.2. Методы сжатия"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSjXxplX-L5M"
      },
      "source": [
        "##### Метод 1: Сжатие на основе ключевых слов (Keyword Extraction)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQpS_2oH-L5N"
      },
      "source": [
        "Ключевые слова помогают выделить основные аспекты запроса, которые будут важны для генерации ответа. Один из популярных инструментов для этого — библиотека KeyBERT, которая использует BERT для нахождения ключевых слов в тексте.\n",
        "\n",
        "\n",
        "**Преимущества**: Простота и быстрая реализация. Полезно в ситуациях, когда запрос достаточно длинный и содержит много уточняющих деталей.  \n",
        "\n",
        "**Недостатки**: Иногда ключевые слова могут не учитывать контекст, и часть важной информации может быть утрачена."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBbUWntX-L5N",
        "outputId": "ab57f351-3089-4789-cdb7-535f084d4fd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compressed Query (Keywords): rag techniques query responses advanced rag advantages using rag\n"
          ]
        }
      ],
      "source": [
        "from keybert import KeyBERT\n",
        "\n",
        "# Инициализация модели KeyBERT\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "def compress_prompt_keywords(query):\n",
        "    # Извлечение топ-5 ключевых слов\n",
        "    keywords = kw_model.extract_keywords(query, keyphrase_ngram_range=(1, 2), stop_words='english', top_n=5)\n",
        "    return \" \".join([word[0] for word in keywords])\n",
        "\n",
        "# Пример использования\n",
        "query = \"What are the main advantages of using advanced RAG techniques for improving query responses?\"\n",
        "compressed_query = compress_prompt_keywords(query)\n",
        "print(\"Compressed Query (Keywords):\", compressed_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKQMJid0-L5P"
      },
      "source": [
        "##### Метод 2: Сжатие на основе извлечения сущностей (Named Entity Recognition, NER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdjzgwHq-L5Q"
      },
      "source": [
        "С помощью NER можно выделить важные сущности, такие как имена людей, даты, локации, которые несут смысловую нагрузку в запросе. Этот метод эффективен для извлечения основных фактов из длинных запросов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BbcmT8u-L5Q"
      },
      "source": [
        "**Преимущества**: Высокая точность при работе с фактологической информацией.  \n",
        "\n",
        "**Недостатки**: При запросах, содержащих описания или абстрактные темы, данный метод может терять важные детали."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e61KqYOX-L5R",
        "outputId": "74cf17fa-42fd-4399-f26d-e386b8b85655"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
            "     -- ------------------------------------- 0.8/12.8 MB 8.3 MB/s eta 0:00:02\n",
            "     --------- ------------------------------ 2.9/12.8 MB 10.5 MB/s eta 0:00:01\n",
            "     --------------- ------------------------ 5.0/12.8 MB 10.1 MB/s eta 0:00:01\n",
            "     ------------------- -------------------- 6.3/12.8 MB 10.2 MB/s eta 0:00:01\n",
            "     ------------------------------ --------- 9.7/12.8 MB 10.8 MB/s eta 0:00:01\n",
            "     ------------------------------------ -- 12.1/12.8 MB 10.9 MB/s eta 0:00:01\n",
            "     --------------------------------------- 12.8/12.8 MB 10.7 MB/s eta 0:00:00\n",
            "Installing collected packages: en-core-web-sm\n",
            "Successfully installed en-core-web-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Compressed Query (Entities): Corrective RAG OpenAI 2024\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "# Загрузка предобученной модели spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def compress_prompt_entities(query):\n",
        "    doc = nlp(query)\n",
        "    # Извлечение только нужных типов сущностей\n",
        "    entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"DATE\", \"TIME\"]]\n",
        "    return \" \".join(entities)\n",
        "\n",
        "# Пример использования\n",
        "query = \"Describe the impact of Corrective RAG introduced by OpenAI in 2024 on information retrieval.\"\n",
        "compressed_query = compress_prompt_entities(query)\n",
        "print(\"Compressed Query (Entities):\", compressed_query)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgbnbPoQ-L5R"
      },
      "source": [
        "##### Метод 3: Сжатие с использованием TF-IDF (Term Frequency - Inverse Document Frequency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amBLfTC4-L5S"
      },
      "source": [
        "TF-IDF помогает выбрать термины, которые наиболее важны для конкретного запроса, на основе их частоты. Этот метод учитывает не только популярные слова, но и те, которые важны именно для данного запроса."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiKVvlxa-L5S"
      },
      "source": [
        "**Преимущества**: Подходит для запросов с большим объемом текста, так как учитывает уникальность терминов.  \n",
        "\n",
        "**Недостатки**: Требует дополнительных данных (контекста) для лучшего определения важных терминов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8dEdhzS-L5S",
        "outputId": "77ff69fe-9934-45bf-8331-b2279e1ab775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compressed Query (TF-IDF): what introduced the advancements are\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def compress_prompt_tfidf(query, documents):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform([query] + documents)\n",
        "    feature_array = vectorizer.get_feature_names_out()\n",
        "    tfidf_sorting = tfidf_matrix[0].toarray().flatten().argsort()[::-1]\n",
        "    # Извлечение топ-5 терминов\n",
        "    top_n = tfidf_sorting[:5]\n",
        "    return \" \".join([feature_array[i] for i in top_n])\n",
        "\n",
        "# Пример использования\n",
        "documents = [\"RAG is a technique for using external data in generation.\", \"Corrective RAG improves response accuracy.\"]\n",
        "query = \"What are the main advancements in RAG models introduced by OpenAI?\"\n",
        "compressed_query = compress_prompt_tfidf(query, documents)\n",
        "print(\"Compressed Query (TF-IDF):\", compressed_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnMKZRJj-L5S"
      },
      "source": [
        "##### Метод 4: Семантическое сжатие с помощью Sentence-BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyGoBuGc-L5T"
      },
      "source": [
        "Модель Sentence-BERT создает компактные векторные представления для запросов и текстов, позволяя сохранять семантическое сходство. Это полезно для сжатия запроса в один или два важных предложения, сохраняя его значение."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTVeT76t-L5T"
      },
      "source": [
        "**Преимущества**: Сохраняет высокий уровень семантического сходства между исходным запросом и сжатым текстом.  \n",
        "\n",
        "**Недостатки**: Зависит от качества обучающих данных и параметров модели, требует дополнительных вычислительных ресурсов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hH_rZXxn-L5T",
        "outputId": "5f1524a5-4402-4fdc-e919-64599479fb85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compressed Query (BERT): Explain the latest advancements in Retrieval-Augmented Generation.\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Инициализация модели Sentence-BERT\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def compress_prompt_bert(query, documents):\n",
        "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "    doc_embeddings = model.encode(documents, convert_to_tensor=True)\n",
        "\n",
        "    # Нахождение наиболее релевантного документа\n",
        "    scores = util.pytorch_cos_sim(query_embedding, doc_embeddings).squeeze()\n",
        "    top_idx = scores.argmax().item()\n",
        "\n",
        "    # Проверка порогового значения\n",
        "    if scores[top_idx] > 0.5:\n",
        "        return documents[top_idx]\n",
        "    else:\n",
        "        return query\n",
        "\n",
        "# Пример использования\n",
        "documents = [\"Advanced RAG models use corrective techniques.\", \"Adaptive RAG allows for flexible query adjustments.\"]\n",
        "query = \"Explain the latest advancements in Retrieval-Augmented Generation.\"\n",
        "compressed_query = compress_prompt_bert(query, documents)\n",
        "print(\"Compressed Query (BERT):\", compressed_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ewCsELZ-L5U"
      },
      "source": [
        "### 1.3. Оптимизация запросов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qn7iSlh-L5U"
      },
      "source": [
        "**Адаптация к сложности задачи**: Оптимизация позволяет выбрать параметры модели в зависимости от сложности запроса. Например, для длинных и сложных запросов может быть полезно задать более низкий параметр temperature, чтобы получить более последовательный и конкретный ответ.  \n",
        "\n",
        "**Управление длиной ответа**: Настройка параметра max_tokens для ограничения длины генерируемого ответа.  \n",
        "\n",
        "**Контроль уровня детальности**: Например, использование top_p и frequency_penalty, чтобы избежать избыточной детализации или чрезмерных повторений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2W21HU5W-L5U",
        "outputId": "13fd420b-47ce-45c8-d3ab-88a53ac96917"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "# Load environment variables\n",
        "load_dotenv('.env')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yUvqwOT-L5V",
        "outputId": "0f35a86c-c79d-4482-ae9b-a2f7e97b8eaa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\basil\\AppData\\Local\\Temp\\ipykernel_11316\\580912320.py:11: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
            "  response = llm(query)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimized Query Response: \n",
            "\n",
            "1. Real-time monitoring and reporting: Adaptive RAG allows for real-time monitoring and reporting of data in large-scale information systems. This enables organizations to quickly identify and address any issues or anomalies, leading to improved decision-making and problem-solving.\n",
            "\n",
            "2. Flexibility and adaptability: Adaptive RAG can be customized and adapted to the specific needs and requirements of different information systems. This flexibility allows for better integration with existing systems and processes, making it easier to manage and analyze large amounts of data.\n",
            "\n",
            "3. Improved data accuracy: By continuously monitoring and updating data, Adaptive RAG helps to ensure the accuracy and reliability of information in large-scale systems. This reduces the risk of errors and improves the overall quality of data.\n",
            "\n",
            "4. Enhanced data visualization:\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "def optimized_query(query):\n",
        "    # Настройка параметров на основе длины запроса\n",
        "    if len(query) > 50:\n",
        "        llm = OpenAI(temperature=0.2, max_tokens=150, top_p=0.85)\n",
        "    else:\n",
        "        llm = OpenAI(temperature=0.7, max_tokens=100, top_p=0.95)\n",
        "\n",
        "    # Выполнение запроса\n",
        "    response = llm(query)\n",
        "    return response\n",
        "\n",
        "# Пример использования\n",
        "query = \"What are the primary benefits of using Adaptive RAG in large-scale information systems?\"\n",
        "response = optimized_query(query)\n",
        "print(\"Optimized Query Response:\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94QoQZHH-L5W"
      },
      "source": [
        "**Temperature**: Контролирует степень вариативности в ответе. Более высокие значения дают более креативные ответы.  \n",
        "\n",
        "**Max Tokens**: Ограничивает длину ответа, что полезно для упрощения обработки.  \n",
        "\n",
        "**Top-p**: Применяет фильтрацию по вероятности, позволяя модели генерировать более целенаправленные ответы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IORbZIj3-L5W"
      },
      "source": [
        "## 2. Продвинутые техники RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMEkMKSB-L5W"
      },
      "source": [
        "### 2.1. Введение в продвинутые техники RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NSiY_UK-L5W"
      },
      "source": [
        "#### 2.1.1. Проблемы базового RAG или почему стандартного RAG недостаточно?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeixcSkm-L5W"
      },
      "source": [
        "Retrieval-Augmented Generation (RAG) — это подход, который объединяет поиск информации и генерацию текста, что позволяет LLM (Large Language Models) получать доступ к информации из внешних источников, таких как базы данных, Википедия и другие документы. Стандартный RAG состоит из двух основных этапов:\n",
        "\n",
        "- **Retrieval (Поиск):** выбор наиболее релевантных документов для запроса.\n",
        "- **Generation (Генерация):** использование этих документов для генерации ответа с помощью модели.\n",
        "\n",
        "Хотя RAG значительно улучшает способность моделей к обработке информации, у этого метода есть несколько ограничений:\n",
        "\n",
        "1. **Зависимость от качества и релевантности извлечённых данных:** стандартный RAG полагается на несколько документов, которые могут не всегда идеально соответствовать запросу. Если подобранные документы недостаточно точные, это напрямую влияет на качество ответа.\n",
        "2. **Ограниченная способность к корректировке неверных данных:** модель RAG генерирует текст на основе извлечённой информации, но при наличии несоответствий или неверной информации в документах, модель не может автоматически исправить эти ошибки.\n",
        "3. **Отсутствие адаптивности к сложности запроса:** стандартный RAG не учитывает специфику запроса. Он одинаково обрабатывает простые и сложные запросы, что может приводить к избыточной или недостаточной информации в ответе.\n",
        "4. **Ресурсоемкость и скорость:** стандартный RAG требует значительных вычислительных ресурсов для работы с большими наборами данных. Извлечение и генерация могут быть медленными и дорогими при обработке сложных или масштабных запросов.\n",
        "\n",
        "Эти ограничения часто становятся особенно заметными в приложениях, где точность и надежность информации играют критическую роль — например, в медицинских системах, юридических консультациях и научных исследованиях.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTATsBbz-L5W"
      },
      "source": [
        "#### 2.1.2. Какие задачи требуют продвинутых техник RAG?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyXuHqpK-L5X"
      },
      "source": [
        "Продвинутые техники RAG разработаны для того, чтобы решать задачи, которые стандартный RAG не может выполнить на должном уровне. Рассмотрим несколько сценариев, где использование стандартного RAG приводит к неудовлетворительным результатам и требуется внедрение улучшенных методов:\n",
        "\n",
        "1. **Глубокий анализ и корректировка ответов:** В некоторых случаях пользователи хотят не только получить ответ, но и убедиться, что ответ точно соответствует запросу. Если стандартный RAG даёт недостаточно точный результат, требуется механизм корректировки для повышения качества.\n",
        "   \n",
        "2. **Адаптация модели к уровню сложности запроса:** в приложениях, где запросы имеют сильно различающиеся уровни сложности, необходимы методы, которые могут \"подстраиваться\" под каждый конкретный запрос, обеспечивая максимальную релевантность и точность ответа.\n",
        "\n",
        "3. **Устранение противоречий в данных:** данные, извлечённые из разных источников, могут содержать противоречивую информацию. Стандартный RAG не предназначен для устранения таких расхождений, и продвинутые методы, такие как Corrective RAG, могут помочь в решении этой проблемы.\n",
        "\n",
        "4. **Контекстно-зависимые запросы:** в некоторых системах требуется обработка запросов с учётом истории взаимодействий пользователя или предыдущих запросов. Стандартный RAG не сохраняет \"память\" об этих взаимодействиях, поэтому необходимо использовать подходы, позволяющие учитывать прошлую информацию, как в Self-RAG.\n",
        "\n",
        "5. **Универсальность в обработке разных типов данных:** стандартный RAG ограничен текстовыми источниками. Если запросы касаются данных разного формата (например, графов, изображений, аудиофайлов), нужны методы, способные адаптироваться к этим особенностям и работать с разными типами данных.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cFOkH48-L5X"
      },
      "source": [
        "#### 2.1.3. Основные направления улучшений и продвинутые техники RAG\n",
        "\n",
        "Существуют несколько подходов к улучшению RAG, каждый из которых решает определённый набор задач. Рассмотрим основные техники и их цели:\n",
        "\n",
        "#### 1. Corrective RAG\n",
        "\n",
        "- **Назначение:** направлен на корректировку ответов, полученных от RAG, для улучшения их точности.\n",
        "- **Принцип работы:** включает дополнительный модуль, который анализирует ответ, сгенерированный моделью, и проверяет его на соответствие исходному запросу. Если ответ содержит неточности, он корректируется, и генерируется новый, уточнённый вариант.\n",
        "- **Применение:** подходит для областей, где важна высокая точность, таких как медицина или право, где ошибка в ответе может привести к негативным последствиям.\n",
        "\n",
        "#### 2. Self-RAG\n",
        "\n",
        "- **Назначение:** Self-RAG позволяет системе сохранять \"память\" о прошлых запросах и ответах, обеспечивая более контекстно-зависимую генерацию ответов.\n",
        "- **Принцип работы:** вместо простого поиска релевантных документов Self-RAG также обращает внимание на предыдущие запросы и ответы, помогая таким образом сохранить связность и непрерывность взаимодействия с пользователем.\n",
        "- **Применение:** идеален для сервисов поддержки клиентов или консультационных систем, где важен учет контекста предыдущих вопросов.\n",
        "\n",
        "#### 3. Adaptive RAG\n",
        "\n",
        "- **Назначение:** автоматическая адаптация параметров генерации ответа в зависимости от сложности и длины запроса.\n",
        "- **Принцип работы:** в Adaptive RAG параметры модели, такие как `temperature`, `max_tokens`, и другие, изменяются динамически в зависимости от структуры запроса. Например, более длинные запросы могут обрабатываться с меньшей температурой для увеличения согласованности ответа, тогда как более простые запросы могут требовать большей вариативности.\n",
        "- **Применение:** эффективен для приложений, где вопросы могут варьироваться от очень простых до сложных, требующих развернутых ответов.\n",
        "\n",
        "#### 4. Prompt Compression and Query Optimization\n",
        "\n",
        "- **Назначение:** упрощение и оптимизация входных данных (запросов), чтобы они содержали только ключевую информацию и занимали меньше ресурсов.\n",
        "- **Принцип работы:** включает предварительную обработку запросов для извлечения наиболее значимых элементов текста, таких как ключевые слова, сущности или важные фразы, что помогает снизить нагрузку на систему.\n",
        "- **Применение:** полезен в ситуациях, где важно экономить вычислительные ресурсы или обрабатывать большие объемы запросов в ограниченные сроки.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51ySu92f-L5X"
      },
      "source": [
        "### 2.2. Corrective RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPuDTeIl-L5Y"
      },
      "source": [
        "[Shi-Qi Yan and Jia-Chen Gu and Yun Zhu and Zhen-Hua Ling. Corrective Retrieval Augmented Generation](https://arxiv.org/abs/2401.15884)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woTgWWgz-L5Y"
      },
      "source": [
        "#### 2.2.1. Зачем нужен Corrective RAG?\n",
        "\n",
        "Corrective RAG необходим в ситуациях, когда стандартный RAG допускает ошибки при генерации ответа. Эти ошибки могут возникать по нескольким причинам:\n",
        "\n",
        "1. **Неоднозначность запроса:**\n",
        "   - некоторые запросы могут включать сложные или двусмысленные формулировки. Стандартный RAG не всегда способен корректно интерпретировать такие запросы, что приводит к ответам, не полностью отражающим суть вопроса.\n",
        "   \n",
        "2. **Противоречивость данных:**\n",
        "   - при извлечении информации из нескольких источников некоторые данные могут конфликтовать между собой. Например, один документ может содержать одну интерпретацию событий, а другой – противоположную. В таких случаях модель может не выбрать наиболее подходящий источник, что приведет к некорректной генерации.\n",
        "\n",
        "3. **Частичная релевантность:**\n",
        "   - документы, выбранные стандартным RAG, могут частично подходить к запросу, но не полностью, и в результате ответ оказывается неполным или неточным.\n",
        "\n",
        "4. **Роль пользователя в критически важных системах:**\n",
        "   - В ряде сфер (например, здравоохранение, финансы или право) ошибки в ответах могут иметь серьезные последствия. Там, где требуется максимальная точность, Corrective RAG может помочь минимизировать риски.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbZA4Eiu-L5Z"
      },
      "source": [
        "#### 2.2.2. Принцип работы Corrective RAG\n",
        "\n",
        "Corrective RAG добавляет ещё один слой контроля и корректировки после этапа генерации. Основные компоненты архитектуры Corrective RAG:\n",
        "\n",
        "1. **Модуль извлечения информации (Retrieval):**\n",
        "   - на этом этапе модель извлекает релевантные документы, как и в стандартном RAG, но при этом используется улучшенная фильтрация и предобработка данных для минимизации рисков.\n",
        "   \n",
        "2. **Генерация (Generation):**\n",
        "   - модель формирует начальный ответ на основе извлечённых данных, однако этот ответ ещё не считается окончательным.\n",
        "   \n",
        "3. **Модуль коррекции (Corrective Module):**\n",
        "   - на этом этапе система проверяет сгенерированный ответ на соответствие запросу и наличию ошибок. Этот модуль может использовать дополнительные модели и алгоритмы для анализа текста и выявления противоречий.\n",
        "\n",
        "4. **Повторная генерация или уточнение ответа:**\n",
        "   - если модуль коррекции обнаруживает ошибки или неточности, система может повторить генерацию с уточнёнными параметрами, чтобы добиться лучшего результата."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VotCH6lj-L5Z"
      },
      "source": [
        "#### 2.2.3. Методы корректировки в Corrective RAG\n",
        "\n",
        "Существует несколько подходов к корректировке ошибок, которые применяются в Corrective RAG:\n",
        "\n",
        "1. **Сравнение с ключевыми фактами и сущностями:**\n",
        "   - Этот метод использует заранее определенные сущности и ключевые факты, которые модель должна включить в ответ. Модуль коррекции проверяет, упоминаются ли эти элементы в ответе. Если какой-то важный факт отсутствует, модель может перегенерировать ответ, чтобы включить его.\n",
        "   \n",
        "2. **Анализ противоречий:**\n",
        "   - Система может использовать алгоритмы на основе правил или модели, чтобы проверить, не содержит ли ответ противоречий. Например, если ответ ссылается на разные даты для одного и того же события, модель корректирует это расхождение.\n",
        "\n",
        "3. **Контекстная проверка запроса и ответа:**\n",
        "   - Модуль коррекции может оценивать, насколько ответ подходит к контексту запроса. Если ответ кажется слишком общим или не полностью отвечает на вопрос, модель уточняет ответ, добавляя нужные детали.\n",
        "\n",
        "4. **Коррекция с помощью дополнительных примеров:**\n",
        "   - Corrective RAG может использовать базу дополнительных примеров ответов, чтобы сопоставить сгенерированный ответ с эталонными ответами и скорректировать его на основе найденных отклонений.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBeJMADV-L5Z"
      },
      "source": [
        "#### 2.2.4. Пример реализации Corrective RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY_88Owp-L5j"
      },
      "source": [
        "Рассмотрим реализацию Corrective RAG с использованием реального ретривера на основе TF-IDF в LangChain. В данном примере создается база данных документов о достижениях Никола Теслы и применяется коррекция ответа для уточнения результата."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gO1FMhsA-L5j",
        "outputId": "4b1c7e8c-a858-4566-ab25-ce6a1feb7697"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Исходный запрос: Расскажите о достижениях Никола Тесла в области электричества.\n",
            "Исправленный запрос: Расскажите о достижениях Никола Тесла в области электричества.. Пожалуйста, укажите: электричество, генератор переменного тока.\n",
            "Ответ после корректировки:  Никола Тесла был известен своими значительными достижениями в области электричества. Он разработал систему переменного тока, которая стала основой для современных систем электроснабжения. Тесла также изобрел индукционный мотор и генератор переменного тока, которые существенно улучшили производительность и эффективность электрических систем. Он также работал над передовыми технологиями передачи энергии и радиосвязи, что сделало его одним из наиболее значимых ученых в области электротехники и физики.\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.retrievers import TFIDFRetriever\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.schema import Document\n",
        "\n",
        "# База документов для примера, преобразуем каждый документ в объект Document\n",
        "documents = [\n",
        "    Document(page_content=\"Никола Тесла был инженером и изобретателем, который разработал систему переменного тока.\"),\n",
        "    Document(page_content=\"Его вклад в электротехнику включает создание индукционного мотора и генератора переменного тока.\"),\n",
        "    Document(page_content=\"Тесла также работал над передовыми технологиями передачи энергии и радиосвязи.\"),\n",
        "    Document(page_content=\"Известно, что Тесла разработал первый индукционный двигатель, работающий на переменном токе.\"),\n",
        "    Document(page_content=\"Никола Тесла является одним из наиболее значительных учёных в области электротехники и физики.\"),\n",
        "]\n",
        "\n",
        "# Разделение документов на фрагменты для улучшения поиска\n",
        "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# Создание индекса TF-IDF для поиска по текстам\n",
        "# Создаем новый список документов для TFIDFRetriever\n",
        "retriever = TFIDFRetriever.from_documents(texts)\n",
        "\n",
        "# Настройка модели и QA-цепочки для генерации ответа\n",
        "llm = OpenAI(temperature=0.2)\n",
        "qa_chain = load_qa_chain(llm=llm, chain_type=\"stuff\")\n",
        "\n",
        "# Определяем запрос и запускаем генерацию\n",
        "query = \"Расскажите о достижениях Никола Тесла в области электричества.\"\n",
        "print(\"Исходный запрос:\", query)\n",
        "relevant_texts = retriever.get_relevant_documents(query)\n",
        "initial_answer = qa_chain.run(input_documents=relevant_texts, question=query)\n",
        "\n",
        "# Определяем модуль коррекции\n",
        "def corrective_module(answer, query):\n",
        "    # Определяем ключевые сущности для данного запроса\n",
        "    required_entities = [\"Никола Тесла\", \"электричество\", \"достижения\", \"генератор переменного тока\"]\n",
        "\n",
        "    # Проверяем, содержит ли ответ все необходимые сущности\n",
        "    missing_entities = [entity for entity in required_entities if entity not in answer]\n",
        "\n",
        "    if missing_entities:\n",
        "        # Если не хватает сущностей, корректируем запрос\n",
        "        refined_query = f\"{query}. Пожалуйста, укажите: {', '.join(missing_entities)}.\"\n",
        "        print(\"Исправленный запрос:\", refined_query)  # Печать исправленного запроса\n",
        "        # Повторный поиск и генерация ответа\n",
        "        relevant_texts = retriever.get_relevant_documents(refined_query)\n",
        "        corrected_answer = qa_chain.run(input_documents=relevant_texts, question=refined_query)\n",
        "        return corrected_answer\n",
        "    return answer\n",
        "\n",
        "# Применение коррекции\n",
        "final_answer = corrective_module(initial_answer, query)\n",
        "print(\"Ответ после корректировки:\", final_answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsRE5V11-L5k"
      },
      "source": [
        "**Пояснение**:\n",
        "\n",
        "1. **База документов**:\n",
        "   - добавляем документы о достижениях Теслы в электротехнике.\n",
        "2. **Text Splitter**:\n",
        "   - этот компонент разбивает большие документы на небольшие фрагменты, чтобы улучшить поиск и сделать извлечение информации более точным.\n",
        "3. **TF-IDF индекс**:\n",
        "   - используется для эффективного извлечения наиболее релевантных документов из базы данных на основе текста запроса.\n",
        "\n",
        "\n",
        "**Пример работы кода**:\n",
        "1. **Первичный запрос**: \"Расскажите о достижениях Никола Тесла в области электричества.\"\n",
        "2. **Первоначальный ответ**: \"Никола Тсела был инженером и изобретателем, который внёс большой вклад в электротехнику.\"\n",
        "3. **Корректировка**: Модуль коррекции добавляет уточнение, и итоговый запрос становится: \"Расскажите о достижениях Никола Тесла в области электричества. Пожалуйста, укажите: генератор переменного тока.\"\n",
        "4. **Корректированный ответ**: \"Никола Тесла разработал генератор переменного тока, который сыграл ключевую роль в развитии современной электротехники.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdOXOh3J-L5k"
      },
      "source": [
        "#### Заключение\n",
        "\n",
        "Corrective RAG представляет собой улучшенную версию стандартного RAG, которая включает механизм обратной связи для корректировки ошибок модели при генерации ответов. Этот подход особенно эффективен в случаях, когда:\n",
        "- **Запросы требуют высокой точности:** Corrective RAG позволяет снизить количество ошибок и неполных ответов, применяя обратную связь и донастройку ретривера для повышения качества извлеченных данных.\n",
        "- **Процесс обучения модели недостаточен:** В ситуациях, когда стандартная модель не справляется с задачей из-за отсутствия специфических знаний, Corrective RAG помогает корректировать и дорабатывать ответы, используя информацию, полученную в ходе предыдущих взаимодействий.\n",
        "- **Сложные вопросы требуют итеративного подхода:** Corrective RAG поддерживает цикличную доработку ответа, что особенно полезно для многослойных вопросов, требующих уточнений и доработок.\n",
        "\n",
        "Corrective RAG идеально подходит для приложений, где важна точность и требуется подробный анализ, таких как юридические консультации, техническая поддержка или обучение. За счет обратной связи и корректировки извлекаемых данных данный метод помогает избежать распространенных ошибок и повышает удовлетворенность пользователей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyODS7zH-L5k"
      },
      "source": [
        "Реализация Corrective RAG с использованием LangGraph [Corrective RAG (CRAG) using LangGraph](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_crag/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOIyPIDC-L5k"
      },
      "source": [
        "### 2.3. Self-RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txa7CxSM-L5k"
      },
      "source": [
        "#### 2.3.1. Введение в Self-RAG\n",
        "\n",
        "**Self-RAG (Self-Retrieving Augmented Generation)** — это подход, при котором модель сама инициирует дополнительные запросы к системе поиска, чтобы обогатить свой ответ. Self-RAG полезен в случаях, когда исходный ответ неполон, а модель должна сама решить, какие дополнительные сведения нужны для завершения ответа.\n",
        "\n",
        "**Особенности Self-RAG:**\n",
        "- **Самостоятельное уточнение запроса:** Self-RAG позволяет модели анализировать ответ и определять, когда и какие дополнительные данные могут быть полезны.\n",
        "- **Обработка сложных запросов:** Self-RAG применяется для сложных вопросов, которые требуют нескольких этапов поиска и генерации информации.\n",
        "- **Гибкость и адаптивность:** Использование Self-RAG делает модель более гибкой, поскольку она способна решать, что требуется для создания более полного ответа.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmLJDJp7-L5k"
      },
      "source": [
        "#### 2.3.2. Проблемы, решаемые Self-RAG\n",
        "\n",
        "1. **Неполнота информации в одном запросе:**\n",
        "   - иногда начальный запрос не может охватить всю информацию, необходимую для создания полноценного ответа. Self-RAG помогает преодолеть это, выполняя дополнительные запросы по мере необходимости.\n",
        "\n",
        "2. **Автоматизация поиска дополнительных данных:**\n",
        "   - без Self-RAG дополнительные запросы и уточнения обычно задаются вручную. В Self-RAG этот процесс автоматизируется, что упрощает получение необходимых данных.\n",
        "\n",
        "3. **Минимизация ручного вмешательства:**\n",
        "   - self-RAG позволяет модели быть автономной в извлечении информации. Это снижает необходимость в ручном вмешательстве и делает процесс более эффективным.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjXjRwCJ-L5l"
      },
      "source": [
        "#### 2.3.3. Применение Self-RAG на практике\n",
        "\n",
        "Примером может служить ситуация, когда система отвечает на сложные исторические или научные запросы, которые требуют нескольких уточнений для полноты. Например, запрос о жизни и достижениях какого-либо ученого может требовать дополнительного поиска по разным аспектам: его открытиям, влиянию, значимости для науки и т.д.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXwm2knG-L5l"
      },
      "source": [
        "#### 2.3.4. Пример реализации Self-RAG\n",
        "\n",
        "В LangChain Self-RAG можно реализовать с помощью каскадных запросов, где модель анализирует начальный ответ и формирует новые уточняющие запросы при необходимости. Ниже приведен пример кода, демонстрирующий реализацию Self-RAG.  \n",
        "Пример основан на LangChain и LangGraph, где модель после начального ответа анализирует его на полноту и, если чего-то не хватает, самостоятельно формирует новый запрос.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nt2kNFlE-L5l",
        "outputId": "c5550da3-ea90-4220-b5e0-ded166baaecc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Первоначальный ответ:  Никола Тесла был известен своими разработками в области электротехники и радиосвязи, включая эксперименты с беспроводной передачей энергии. Он изобрел генератор переменного тока и индукционный мотор, которые стали основой для современных систем электропередачи. Тесла также изучал влияние электромагнитных волн и создал первую радиостанцию, что позволило ему доказать возможность беспроводной передачи энергии на большие расстояния. Его исследования и изобретения в области передачи энергии сыграли важную роль в развитии современных технологий и оказали значительное влияние на\n",
            "Итоговый ответ с Self-RAG:  Никола Тесла был известен своими разработками в области электротехники и радиосвязи, включая эксперименты с беспроводной передачей энергии. Он изобрел генератор переменного тока и индукционный мотор, которые стали основой для современных систем электропередачи. Тесла также изучал влияние электромагнитных волн и создал первую радиостанцию, что позволило ему доказать возможность беспроводной передачи энергии на большие расстояния. Его исследования и изобретения в области передачи энергии сыграли важную роль в развитии современных технологий и оказали значительное влияние на Дополнительные сведения:  Никола Тесла был известен своими разработками в области электротехники и радиосвязи. Он изобрел генератор переменного тока и индукционный мотор, что позволило эффективно передавать энергию на большие расстояния. Также Тесла изучал влияние электромагнитных волн и создал первую радиостанцию, что сыграло важную роль в развитии радиосвязи. Его эксперименты с беспроводной передачей энергии также стали значимым вкладом в эту область.\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.retrievers import TFIDFRetriever\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Инициализируем базу документов\n",
        "documents = [\n",
        "    \"Никола Тесла был известен своими разработками в области электротехники и радиосвязи.\",\n",
        "    \"Тесла изобрел генератор переменного тока и индукционный мотор.\",\n",
        "    \"Работы Теслы стали важной основой для развития современной электротехники.\",\n",
        "    \"Его вклад включает эксперименты с беспроводной передачей энергии.\",\n",
        "    \"Тесла также изучал влияние электромагнитных волн и создал первую радиостанцию.\"\n",
        "]\n",
        "\n",
        "# Разделяем документы для улучшения поиска\n",
        "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
        "\n",
        "# Применяем split_text для каждого документа по отдельности\n",
        "texts = []\n",
        "for doc in documents:\n",
        "    texts.extend(text_splitter.split_text(doc))  # Используем split_text для каждого документа\n",
        "\n",
        "# Создаем список документов для TFIDFRetriever\n",
        "docs = [Document(page_content=text) for text in texts]\n",
        "retriever = TFIDFRetriever.from_documents(docs)\n",
        "\n",
        "# Настройка LLM\n",
        "llm = OpenAI(temperature=0.2)\n",
        "\n",
        "# Создаем цепочку для QA с использованием retriever\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type=\"stuff\")\n",
        "\n",
        "# Определяем запрос\n",
        "query = \"Расскажите о достижениях Никола Тесла в передаче энергии.\"\n",
        "\n",
        "# Запуск начального RAG\n",
        "initial_answer = qa_chain.run(query)\n",
        "print(\"Первоначальный ответ:\", initial_answer)\n",
        "\n",
        "# Функция Self-RAG для самостоятельного уточнения ответа\n",
        "def self_rag(answer, query):\n",
        "    # Проверяем, упомянуты ли ключевые достижения Теслы\n",
        "    required_entities = [\"передача энергии\", \"радиосвязь\", \"электромагнитные волны\"]\n",
        "    missing_entities = [entity for entity in required_entities if entity not in answer]\n",
        "\n",
        "    if missing_entities:\n",
        "        # Формируем новый уточняющий запрос\n",
        "        refined_query = f\"{query}. Пожалуйста, укажите: {', '.join(missing_entities)}.\"\n",
        "        additional_info = qa_chain.run(refined_query)\n",
        "        # Объединяем начальный ответ и дополнительную информацию\n",
        "        full_answer = f\"{answer} Дополнительные сведения: {additional_info}\"\n",
        "        return full_answer\n",
        "    return answer\n",
        "\n",
        "# Применяем Self-RAG для уточнения ответа\n",
        "final_answer = self_rag(initial_answer, query)\n",
        "print(\"Итоговый ответ с Self-RAG:\", final_answer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YzqGapN-L5l"
      },
      "source": [
        "**Пояснение**:  \n",
        "\n",
        "1. **Инициализация базы документов**:\n",
        "   - создаётся набор текстов, охватывающих основные достижения Никола Теслы.\n",
        "2. **RAG-процесс**:\n",
        "   - изначальный запрос находит информацию о достижениях Теслы. Начальный ответ выводится для анализа.\n",
        "3. **Self-RAG проверка**:\n",
        "   - определяется, содержатся ли ключевые аспекты (такие как передача энергии или электромагнитные волны) в ответе. Если они отсутствуют, генерируется уточняющий запрос.\n",
        "4. **Объединение результатов**:\n",
        "   - если требуется дополнительная информация, она запрашивается и объединяется с начальным ответом, что обеспечивает полноту."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE-ELPCO-L5m"
      },
      "source": [
        "**Пример работы кода**:  \n",
        "\n",
        "**Первичный запрос**: \"Расскажите о достижениях Никола Тесла в передаче энергии.\"  \n",
        "**Первоначальный ответ**: \"Никола Тесла был известен своими разработками в области электротехники.\"  \n",
        "**Уточняющий запрос**: \"Расскажите о достижениях Никола Тесла в передаче энергии. Пожалуйста, укажите: радиосвязь, электромагнитные волны.\"  \n",
        "**Корректированный ответ**: \"Никола Тесла был известен своими разработками в области электротехники. Дополнительные сведения: Тесла также изучал влияние электромагнитных волн и создал первую радиостанцию.\"  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bVw2UAS-L5m"
      },
      "source": [
        "#### Заключение\n",
        "\n",
        "Self-RAG представляет собой метод, который позволяет модели работать автономно, контролируя процесс поиска и отбора данных для генерации ответа. Этот подход полезен в ситуациях, где:\n",
        "\n",
        "- **Требуется автономность:** Self-RAG дает модели возможность выполнять поиск и выбор информации самостоятельно, минимизируя необходимость внешнего управления и обеспечивая гибкость в обработке запросов.\n",
        "- **Необходимость обработки сложных запросов:** Self-RAG помогает модели разделять и анализировать запросы, адаптируясь к их сложности и при необходимости самостоятельно корректируя выбор ретривера.\n",
        "- **Требования к адаптивности:** Метод Self-RAG позволяет модели анализировать свой собственный ответ и, при необходимости, корректировать его с помощью дополнительного поиска или уточнения информации.\n",
        "\n",
        "Self-RAG подходит для интеллектуальных систем, которым требуется максимальная автономность и точность в ответах, например, для использования в научных исследованиях, аналитике и справочных сервисах. Такой подход позволяет создавать ответы на основе широкого спектра данных и улучшает качество взаимодействия за счет самостоятельной коррекции."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o96aivSD-L5m"
      },
      "source": [
        "### 2.4. Adaptive RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGEDhKjF-L5m"
      },
      "source": [
        "#### 2.4.1. Введение в Adaptive RAG\n",
        "\n",
        "**Adaptive RAG (Adaptive Retrieval-Augmented Generation)** — это метод, при котором модель динамически подбирает наиболее подходящий механизм извлечения информации в зависимости от запроса и его сложности. В отличие от стандартных подходов RAG, которые используют один и тот же тип извлечения для всех запросов, Adaptive RAG анализирует запросы и адаптирует стратегию извлечения, что позволяет повысить точность и релевантность ответов.\n",
        "\n",
        "**Основные особенности Adaptive RAG:**\n",
        "- **Гибкость в обработке запросов:** модель может использовать разные подходы к извлечению данных в зависимости от специфики запроса.\n",
        "- **Оптимизация производительности:** адаптация позволяет использовать простые методы для базовых запросов и более сложные методы для многослойных вопросов, снижая нагрузку на систему.\n",
        "- **Многоуровневое извлечение:** модель может комбинировать несколько методов извлечения, чтобы сформировать более информативные ответы на сложные запросы.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7M2wHRw-L5m"
      },
      "source": [
        "#### 2.4.2. Проблемы, решаемые Adaptive RAG\n",
        "\n",
        "1. **Различные уровни сложности запросов:**\n",
        "   - запросы могут варьироваться от простых фактических вопросов до сложных вопросов, требующих многоступенчатого анализа. Adaptive RAG позволяет модели выбирать подходящий уровень извлечения для каждого типа запроса.\n",
        "2. **Избежание избыточного извлечения:**\n",
        "   - стандартные методы RAG могут возвращать больше данных, чем нужно, даже для простых запросов. Adaptive RAG решает эту проблему, снижая объем ненужной информации.\n",
        "3. **Адаптация к типу запроса:**\n",
        "   - adaptive RAG позволяет модели анализировать запрос и выбирать, какой тип информации наиболее важен для ответа (например, обобщенные данные или конкретные факты).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imI4aLW_-L5m"
      },
      "source": [
        "#### 2.4.3. Применение Adaptive RAG на практике\n",
        "\n",
        "Adaptive RAG особенно полезен, когда модель обслуживает различные типы пользователей (например, экспертов и начинающих) или обрабатывает многослойные запросы. Примером могут быть научные или аналитические системы, где модель должна корректно оценить запрос и выбрать подходящую стратегию поиска.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM5ewUQ1-L5n"
      },
      "source": [
        "#### 2.4.5. Реализация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z6WMGSs-L5n"
      },
      "source": [
        "Adaptive RAG может быть реализован через каскадный метод выбора ретривера или же с использованием логики, анализирующей длину и сложность запроса. В примере ниже мы рассмотрим реализацию, где модель сначала проверяет сложность запроса и выбирает подходящий механизм извлечения: простое TF-IDF для базовых запросов и векторный поиск на основе косинусной близости для более сложных запросов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcjdpzfB-L5n",
        "outputId": "e13970e2-d9fd-4123-fbee-81f91be230ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Используется TF-IDF для простого запроса.\n",
            "Ответ для простого запроса:  Никола Тесла - известный ученый, который внес значительный вклад в области электротехники и радиосвязи. Он также изучал беспроводную передачу энергии и электромагнитные волны, и его работы стали основой для развития современной электротехники. Он также считается одним из самых значимых ученых в истории науки.\n",
            "Используется RAG с векторным индексом для сложного запроса.\n",
            "Ответ для сложного запроса:  Никола Тесла был известен своими разработками в области электротехники и радиосвязи, включая беспроводную передачу энергии и электромагнитные волны. Он провел множество экспериментов и изобрел устройства, которые позволяли передавать энергию без проводов, используя электромагнитные волны. Он также создал первую радио передающую станцию и разработал систему для беспроводной связи на большие расстояния. Работы Теслы стали основой для развития современной электротехники и радиосвязи, и его вклад в науку и технологии до сих пор остается значимым.\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.retrievers import TFIDFRetriever\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chains.question_answering.chain import load_qa_chain\n",
        "from langchain.schema import Document\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "\n",
        "# Документы для примера\n",
        "documents = [\n",
        "    \"Никола Тесла был известен своими разработками в области электротехники и радиосвязи.\",\n",
        "    \"Он изобрел генератор переменного тока и индукционный мотор.\",\n",
        "    \"Работы Теслы стали основой для развития современной электротехники.\",\n",
        "    \"Тесла изучал беспроводную передачу энергии и электромагнитные волны.\",\n",
        "    \"Никола Тесла является одним из самых значимых ученых в истории науки.\"\n",
        "]\n",
        "\n",
        "# Разделяем документы для улучшения поиска\n",
        "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
        "\n",
        "# Применяем split_text для каждого документа по отдельности\n",
        "texts = []\n",
        "for doc in documents:\n",
        "    texts.extend(text_splitter.split_text(doc))\n",
        "\n",
        "# Создаем список документов для TFIDFRetriever\n",
        "docs = [Document(page_content=text) for text in texts]\n",
        "tfidf_retriever = TFIDFRetriever.from_documents(docs)\n",
        "\n",
        "# Настраиваем FAISS векторное хранилище\n",
        "embeddings = OpenAIEmbeddings()\n",
        "faiss_store = FAISS.from_texts(texts, embeddings)\n",
        "faiss_retriever = faiss_store.as_retriever()\n",
        "\n",
        "# Инициализируем модель\n",
        "llm = OpenAI(temperature=0.2)\n",
        "\n",
        "# Создаем цепочку вопросов и ответов\n",
        "llm_chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "# Создаем StuffDocumentsChain с правильным использованием llm_chain\n",
        "#combine_documents_chain = StuffDocumentsChain(llm_chain=llm_chain)\n",
        "\n",
        "# Функция для анализа сложности запроса\n",
        "def is_complex_query(query):\n",
        "    return len(query.split()) > 5 or any(word in query.lower() for word in [\"подробно\", \"объясните\", \"детали\"])\n",
        "\n",
        "# Функция Adaptive RAG\n",
        "def adaptive_rag(query):\n",
        "    is_complex = is_complex_query(query)\n",
        "    if is_complex:\n",
        "        print(\"Используется RAG с векторным индексом для сложного запроса.\")\n",
        "        retriever = faiss_retriever\n",
        "    else:\n",
        "        print(\"Используется TF-IDF для простого запроса.\")\n",
        "        retriever = tfidf_retriever\n",
        "\n",
        "    # Создание RAG цепочки с использованием llm и retriever\n",
        "    rag_chain = RetrievalQA.from_llm(llm=llm, retriever=retriever)\n",
        "    answer = rag_chain.run(query)\n",
        "    return answer\n",
        "\n",
        "# Примеры запросов\n",
        "simple_query = \"Кто такой Никола Тесла?\"\n",
        "complex_query = \"Объясните достижения Никола Теслы в области передачи энергии и электромагнитных волн подробно.\"\n",
        "\n",
        "# Запуск Adaptive RAG для каждого запроса\n",
        "print(\"Ответ для простого запроса:\", adaptive_rag(simple_query))\n",
        "print(\"Ответ для сложного запроса:\", adaptive_rag(complex_query))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBbdVMgL-L5n"
      },
      "source": [
        "**Пояснение к коду**\n",
        "\n",
        "1. **Инициализация базы документов:** Набор текстов о Тесле позволяет создать базу данных для поисковых запросов, предоставляя информацию для обработки запроса на этапе извлечения.\n",
        "2. **TF-IDF и FAISS ретриверы:** Настроены два ретривера:\n",
        "   - `TFIDFRetriever` — для обработки простых запросов.\n",
        "   - `FAISSRetriever` — для работы со сложными запросами, когда необходим более глубокий анализ.\n",
        "3. **Функция `is_complex_query`:** Функция проверяет, является ли запрос сложным, анализируя длину запроса или наличие ключевых слов (например, \"подробно\" или \"объясните\"), которые предполагают более детальный ответ.\n",
        "4. **Adaptive RAG логика:** В зависимости от результата `is_complex_query`, выбирается соответствующий ретривер. Если запрос признан сложным, применяется FAISS, в противном случае — TF-IDF.\n",
        "5. **Запросы и ответы:** На простые запросы система отвечает с помощью TF-IDF, а на сложные — с помощью векторного поиска (FAISS), что оптимизирует процесс поиска и повышает релевантность ответов.\n",
        "\n",
        "**Пример работы кода**\n",
        "\n",
        "1. **Простой запрос:** `\"Кто такой Никола Тесла?\"`\n",
        "   - **Выбранный ретривер:** TF-IDF\n",
        "   - **Ответ:** `\"Никола Тесла был известен своими разработками в области электротехники и радиосвязи.\"`\n",
        "   \n",
        "2. **Сложный запрос:** `\"Объясните достижения Никола Теслы в области передачи энергии и электромагнитных волн подробно.\"`\n",
        "   - **Выбранный ретривер:** FAISS\n",
        "   - **Ответ:** `\"Тесла изучал беспроводную передачу энергии и электромагнитные волны. Его эксперименты в этой области стали важной основой для развития науки.\"`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0elG9b3-L5o"
      },
      "source": [
        "#### Заключение\n",
        "\n",
        "Adaptive RAG позволяет модели динамически адаптироваться к типу запроса, что повышает качество и релевантность ответов, а также снижает нагрузку на систему. Это особенно полезно в ситуациях, когда:\n",
        "- **Запросы различаются по сложности:** Adaptive RAG позволяет подбирать стратегию поиска для каждого запроса индивидуально.\n",
        "- **Производительность критична:** Использование более простых методов для простых запросов и мощных методов для сложных снижает общую нагрузку.\n",
        "- **Требуется высокая точность:** Adaptive RAG позволяет более точно отвечать на сложные вопросы, адаптируя глубину ответа под запрос.\n",
        "\n",
        "Adaptive RAG идеально подходит для профессиональных, научных и аналитических приложений, требующих высокого уровня точности и гибкости при обработке запросов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VILP5s6e-L5o"
      },
      "source": [
        "### 2.5. Сравнение различных подходов RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT64C_4K-L5p"
      },
      "source": [
        "1. **Simple RAG**:\n",
        "   - Используется стандартный подход с RetrievalQA и векторным хранилищем.\n",
        "2. **Corrective RAG**:\n",
        "   - Введен специальный шаблон для исправления ошибок в ответах.\n",
        "3. **Self-RAG**:\n",
        "   - Используется самокоррекция в ответах, дополненная уточняющими деталями.\n",
        "4. **Adaptive RAG**:\n",
        "   - Применяется подход с анализом сложности запроса (с использованием TF-IDF для простых запросов и FAISS для сложных)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoDbybe8-L5p",
        "outputId": "76074878-9bad-4800-9b9a-af200f7dfcce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Используется RAG с векторным индексом для сложного запроса.\n",
            "Simple RAG ответ:\n",
            " Никола Тесла был известным изобретателем, который работал в области электричества и магнетизма. Он изобрел трансформатор Теслы, который позволил передавать энергию на большие расстояния. Тесла был одним из пионеров в области разработки технологий для создания новых типов электродвигателей и генераторов, которые стали основой для последующих инноваций в промышленности. Он также провел знаменитые эксперименты в Колорадо-Спрингс, где ему удалось создать искусственные молнии, что продемонстрировало огромный потенциал высокочастотных электрических волн. Хотя многие из его идей были недооценены в свое время, Тесла оставил неизгладимый след в истории науки и технологий, особенно в области энергетики и телекоммуникаций. В целом, Никола Тесла был великим ученым и изобретателем, чьи достижения продолжают влиять на нашу жизнь и сегодня.\n",
            "--------------------------------------------------\n",
            "\n",
            "Corrective RAG ответ:\n",
            " Никола Тесла был известным изобретателем, который работал в области электричества и магнетизма. Он изобрел трансформатор Теслы, который позволил передавать энергию на большие расстояния. Хотя многие из его идей были недооценены в свое время, Тесла оставил неизгладимый след в истории науки и технологий, особенно в области энергетики и телекоммуникаций. В 1899 году Тесла провел знаменитые эксперименты в Колорадо-Спрингс, где ему удалось создать искусственные молнии, что продемонстрировало огромный потенциал высокочастотных электрических волн. Тесла также был одним из пионеров в области разработки технологий для создания новых типов электродвигателей и генераторов, которые стали основой для последующих инноваций в промышленности.\n",
            "--------------------------------------------------\n",
            "\n",
            "Self-RAG ответ:\n",
            " Никола Тесла был известным изобретателем, который работал в области электричества и магнетизма. Он родился в Хорватии в 1856 году и получил образование в Праге и Граце. В 1884 году он переехал в США, где начал свою карьеру в области электротехники. Он изобрел трансформатор Теслы, который позволил передавать энергию на большие расстояния. Этот изобретение стало основой для создания современной системы электропередачи. \n",
            "\n",
            "Хотя многие из его идей были недооценены в свое время, Тесла оставил неизгладимый след в истории науки и технологий. Он был одним из первых ученых, кто исследовал высокочастотные электрические волны и их потенциал в области энергетики и телекоммуникаций. \n",
            "\n",
            "В 1899 году Тесла провел знаменитые эксперименты в Колорадо-Спрингс, где ему удалось создать искусственные молнии. Это было важным достижением в области электротехники и подтвердило его теорию о возможности передачи энергии без проводов. \n",
            "\n",
            "Тесла также был одним из пионеров в разработке технологий для создания новых типов электродвигателей и генераторов. Его изобретения стали основой для последующих инноваций\n",
            "--------------------------------------------------\n",
            "\n",
            "Adaptive RAG ответ:\n",
            " Никола Тесла был известным изобретателем, который работал в области электричества и магнетизма. Он изобрел трансформатор Теслы, который позволил передавать энергию на большие расстояния. Хотя многие из его идей были недооценены в свое время, Тесла оставил неизгладимый след в истории науки и технологий, особенно в области энергетики и телекоммуникаций. В 1899 году Тесла провел знаменитые эксперименты в Колорадо-Спрингс, где ему удалось создать искусственные молнии, что продемонстрировало огромный потенциал высокочастотных электрических волн. Он также был одним из пионеров в области разработки технологий для создания новых типов электродвигателей и генераторов, которые стали основой для последующих инноваций в промышленности. Тесла был человеком с необычным умом и воображением, что позволило ему придумывать и воплощать в жизнь уникальные идеи. Он также был сторонником использования альтернативных источников энергии и мечтал о создании бесплатной энергии для всех людей. Несмотря на то, что многие из его изобретений не были признаны в свое время, сегодня они являются основой для многих технологий и научных раз\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import RetrievalQA, LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.retrievers import TFIDFRetriever\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains.question_answering.chain import load_qa_chain\n",
        "\n",
        "# Подготовка LLM и эмбеддингов\n",
        "llm = OpenAI(temperature=0.2, max_tokens=512)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Примеры документов о Николе Тесле\n",
        "documents = [\n",
        "    \"Никола Тесла был известным изобретателем, который работал в области электричества и магнетизма. Он изобрел трансформатор Теслы, который позволил передавать энергию на большие расстояния.\",\n",
        "    \"В 1891 году Тесла продемонстрировал передачу энергии без проводов, что стало важным шагом в развитии беспроводных технологий.\",\n",
        "    \"Исследования Теслы в области высокочастотного переменного тока привели к разработке систем, способных передавать электроэнергию без использования проводов на значительные расстояния.\",\n",
        "    \"Работы Теслы легли в основу многих современных технологий, включая радиосвязь и системы передачи данных.\",\n",
        "    \"Тесла также экспериментировал с беспроводной передачей информации и энергии, создав прототипы, которые значительно опережали время. Его работы по радиоволнам стали основой для дальнейших достижений в области телекоммуникаций.\",\n",
        "    \"В 1899 году Тесла провел знаменитые эксперименты в Колорадо-Спрингс, где ему удалось создать искусственные молнии, что продемонстрировало огромный потенциал высокочастотных электрических волн.\",\n",
        "    \"Тесла был одним из пионеров в области разработки технологий для создания новых типов электродвигателей и генераторов, которые стали основой для последующих инноваций в промышленности.\",\n",
        "    \"В 1917 году Тесла предложил концепцию мирового беспроводного радио и связи, которая предвосхитила современную мобильную коммуникацию.\",\n",
        "    \"Хотя многие из его идей были недооценены в свое время, Тесла оставил неизгладимый след в истории науки и технологий, особенно в области энергетики и телекоммуникаций.\"\n",
        "]\n",
        "\n",
        "# Разделение текста на куски для обеспечения правильного поиска\n",
        "splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
        "\n",
        "# Применяем split_text для каждого документа по отдельности\n",
        "texts = []\n",
        "for doc in documents:\n",
        "    texts.extend(splitter.split_text(doc))\n",
        "\n",
        "# Создаем список документов для TFIDFRetriever\n",
        "docs = [Document(page_content=text) for text in texts]\n",
        "\n",
        "\n",
        "\n",
        "# Подготовка векторного хранилища для VectorstoreRetriever\n",
        "vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "vectorstore_retriever = vectorstore.as_retriever()\n",
        "\n",
        "# TF-IDF retriever\n",
        "tfidf_retriever = TFIDFRetriever.from_texts([doc.page_content for doc in docs])\n",
        "\n",
        "# Шаблон для Corrective RAG\n",
        "corrective_template = \"\"\"Ответьте на запрос, используя следующие документы:\n",
        "{context}\n",
        "Запрос: {query}\n",
        "Коррекция: если в ответе есть ошибка или неверная информация, исправьте ее.\n",
        "\n",
        "Ответ:\"\"\"\n",
        "corrective_prompt = PromptTemplate(input_variables=[\"context\", \"query\"], template=corrective_template)\n",
        "\n",
        "# Шаблон для Self-RAG\n",
        "self_rag_template = \"\"\"Ответьте на запрос, используя следующие документы:\n",
        "{context}\n",
        "Запрос: {query}\n",
        "Используйте самокоррекцию, чтобы избежать ошибок в ответе и добавьте уточняющие детали.\n",
        "\n",
        "Ответ:\"\"\"\n",
        "self_rag_prompt = PromptTemplate(input_variables=[\"context\", \"query\"], template=self_rag_template)\n",
        "\n",
        "# Подготовка цепочек для каждого подхода\n",
        "simple_rag = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectorstore_retriever)\n",
        "corrective_rag = LLMChain(llm=llm, prompt=corrective_prompt)\n",
        "self_rag = LLMChain(llm=llm, prompt=self_rag_prompt)\n",
        "\n",
        "# Настройка Adaptive RAG\n",
        "# Инициализация FAISS и настройки цепочек\n",
        "faiss_store = FAISS.from_texts([doc.page_content for doc in docs], embeddings)\n",
        "faiss_retriever = faiss_store.as_retriever()\n",
        "\n",
        "# Функция для анализа сложности запроса\n",
        "def is_complex_query(query):\n",
        "    return len(query.split()) > 5 or any(word in query.lower() for word in [\"подробно\", \"объясните\", \"детали\"])\n",
        "\n",
        "# Функция Adaptive RAG\n",
        "def adaptive_rag(query):\n",
        "    is_complex = is_complex_query(query)\n",
        "    if is_complex:\n",
        "        print(\"Используется RAG с векторным индексом для сложного запроса.\\n\\n\")\n",
        "        retriever = faiss_retriever\n",
        "    else:\n",
        "        print(\"Используется TF-IDF для простого запроса.\\n\\n\")\n",
        "        retriever = tfidf_retriever\n",
        "\n",
        "    # Создание RAG цепочки с использованием llm и retriever\n",
        "    rag_chain = RetrievalQA.from_llm(llm=llm, retriever=retriever)\n",
        "    answer = rag_chain.run(query)\n",
        "    return answer\n",
        "\n",
        "# Функция для выполнения запроса с каждым подходом\n",
        "def compare_rag_approaches(query):\n",
        "    responses = {}\n",
        "\n",
        "    # Simple RAG\n",
        "    responses['Simple RAG'] = simple_rag.run(query)\n",
        "\n",
        "    # Corrective RAG\n",
        "    context = vectorstore_retriever.get_relevant_documents(query)\n",
        "    responses['Corrective RAG'] = corrective_rag.run({\"context\": context, \"query\": query})\n",
        "\n",
        "    # Self-RAG\n",
        "    responses['Self-RAG'] = self_rag.run({\"context\": context, \"query\": query})\n",
        "\n",
        "    # Adaptive RAG\n",
        "    responses['Adaptive RAG'] = adaptive_rag(query)\n",
        "\n",
        "    return responses\n",
        "\n",
        "# Пример использования\n",
        "#query = \"Объясните достижения Никола Теслы в области передачи энергии и электромагнитных волн подробно.\"\n",
        "query = \"Расскажи подробно про Никола Тесла.\"\n",
        "results = compare_rag_approaches(query)\n",
        "\n",
        "# Вывод результатов для сравнения\n",
        "for approach, response in results.items():\n",
        "    print(f\"{approach} ответ:\\n{response}\\n{'-'*50}\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}